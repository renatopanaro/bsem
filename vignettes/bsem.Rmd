---
title: "bsem"
subtitle: "An R package for Bayesian structural equation modeling"
author: 
  - name          : "Renato V. Panaro"
    affiliation   : "Departamento de Estatística, IME, Universidade de São Paulo"
    corresponding : yes
    address       : "São Paulo-SP, Brazil"
    email         : "renatovp@ime.usp.br"
  - name          : "Vinicius D. Mayrink"
    affiliation   : "Departamento de Estatística, ICEx, Universidade de Federal de Minas Gerais"
    corresponding : no
    address       : "Belo Horizonte-MG, Brazil"
    email         : "vdinizm@gmail.com"
  - name          : "Marcelo A. Costa"
    affiliation   : "Departamento de Engenharia de Produção, Escola de Engenharia, Universidade de Federal de Minas Gerais"
    corresponding : no
    address       : "Belo Horizonte-MG, Brazil"
    email         : "macosta.est@gmail.com"    

keywords          : "structural equation model, factor analysis"
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
      toc_number: true
vignette: >
  %\VignetteIndexEntry{Get started}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

<style>
body {
text-align: justify
</style>

```{r, echo = F}
set.seed(2020)
```

# Introduction

This vignette introduces the `bsem` package routines. This package was designed to allow particular cases of structural equation models (SEMs) in `R`. Examples include confirmatory factor analysis (CFA) and confirmatory SEM. The flexible full SEM model (outer model + inner model), implemented here, enables the evaluation of user-defined constructs (latent variables) along with the analysis of established relationships among the latent scores (factors depending on other factors) and/or exogenous variables (variables depending on factors).

Factor analysis (FA) is a powerful and flexible tool to investigate the multivariate dependence in a data set. The main aim is to reduce dimension, i.e., summarize the information expressed in multiple observed variables. The summarization process involves the construction of a few unobserved latent factors representing the existing subjacent patterns in the data. The usual FA can be divided into two types: exploratory (EFA) and confirmatory (CFA). The EFA does not impose any restriction on the relationship between latent factors and observed variables (the model is free to establish such associations). The CFA accounts for the technical information regarding the connections between observed and latent variables; examples of applications involving the CFA can be found in [Brown](https://www.guilford.com/books/Confirmatory-Factor-Analysis-for-Applied-Research/Timothy-Brown/9781462515363) (2015). In this case, the researcher must impose that a factor is exclusively explained by a group of observed variables. The CFA is widely used in the context of SEM, see the references  [Lee and Song](https://link.springer.com/article/10.1007/BF02296651) (2003), [Skrondal and Rabe-Hesketh](https://www.routledge.com/Generalized-Latent-Variable-Modeling-Multilevel-Longitudinal-and-Structural/Skrondal-Rabe-Hesketh/p/book/9781584880004) (2004), [Palomo, Dunson, and Bollen](https://www.elsevier.com/books/handbook-of-latent-variable-and-related-models/lee/978-0-444-52044-9) (2007), [Hoyle](https://www.guilford.com/books/Handbook-of-Structural-Equation-Modeling/Rick-Hoyle/9781462516797) (2014) and [Keith](https://www.routledge.com/Multiple-Regression-and-Beyond-An-Introduction-to-Multiple-Regression/Keith/p/book/9781138061446)(2019). Besides the EFA and CFA, it is possible to work with an intermediate case combining these two types. This option can be seen as a semi-confirmatory FA and an example is described in [Mayrink and Lucas](https://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aoas/1372338468) (2013) and [Mayrink and Lucas](https://projecteuclid.org/euclid.bjps/1414674773) (2015).

The structure of an SEM has two parts, one involving a CFA and another with multiple regression equations. For an overview of SEMs, it is recommended to read the work [Sanchez et al.](https://www.jstor.org/stable/27590684?seq=1) (2005), which is focused on applications in epidemiology. The studies [Anderson and Gerbing](https://psycnet.apa.org/doiLanding?doi=10.1037%2F0033-2909.103.3.411) (1988) and [MacCallum and Austin](https://doi.org/10.1146/annurev.psych.51.1.201) (2000) provide an overview of the use of SEM in psychology. Examples using SEMs in the context of Bayesian inference are discussed in [Palomo, Dunson, and Bollen](https://www.elsevier.com/books/handbook-of-latent-variable-and-related-models/lee/978-0-444-52044-9) (2007). A clear advantage of using the Bayesian approach is the fact that asymptotic assumptions, required by frequentist maximum likelihood methods, may not be valid depending on the sample size. The reference [Lee and Song](https://link.springer.com/article/10.1007/BF02296651) (2003) highlights the good performance of the Bayesian SEM in a comparison with the frequentist version.

Consider:

- the outer model (blocks) as:
$$\boldsymbol{X_{p\times n}} = \boldsymbol{\alpha}_{p\times k}\boldsymbol{\lambda}_{k\times n} +\boldsymbol{\varepsilon}_{p\times n}$$
where $\boldsymbol{X}$ is the data matrix with variables in the rows and sample elements in the columns,  $\boldsymbol{\alpha}_{p\times j}$ is the column vector of loadings for the $j^{th}$ latent variable and $\boldsymbol{\lambda}_{j\times n}$ is the row vector of scores for the  $j^{th}$ unobserved variable,$~j =1,\dots,k$. Normality is assumed for the errors as $\boldsymbol{\varepsilon}_{ij}\sim N(0, \sigma_{i}^2)$ for $i = 1,\dots, p$.

- the inner model as:
  - paths:
$$\boldsymbol{\lambda}_{j\times n} = \boldsymbol{\beta}^{\top} {\lambda^{(-j)}}  + \nu~$$
where $\boldsymbol{\beta}$ is a column vector of constant coefficients, ${\lambda^{(-j)}}_{ (k-1)\times n}$ represents a subset of the matrix of scores, i.e. at least excluding the $j^{th}$ row scores. The errors are independent and assume $\nu_j \sim N(0,1)$.

  - exogenous:
$$\boldsymbol{Y}_{l\times n} = \boldsymbol{\gamma_0} + \boldsymbol{\gamma}^{\top} {\lambda}  + \xi~$$
where $\boldsymbol{\gamma}$ is a column vector of constant coefficients and $\boldsymbol{\gamma_0}$ is the intercept. $\lambda_{k \times n}$ is the matrix of scores. The errors are independent and assume $\xi_l\sim N(0,\tau_l^2)$.

The guidelines in this document were divided into 4 sections: [installation](#installation), [description](#description), [usage](#usage), and [remarks](#remarks).

# Installation

The ``bsem`` package imports  ``Stan`` software specific routines to support internal calculations. The [``rstan``](https://mc-stan.org/users/interfaces/rstan) package interface enables the use of the NUTS algorithm ( [Hoffman and Gelman, 2014](http://www.stat.columbia.edu/~gelman/research/published/nuts.pdf))  to explore the posterior distribution efficiently in R. The development version of ``bsem`` can be found in [github.com/rvpanaro/bsem](https://github.com/rvpanaro/bsem).

For github version:

```{r, eval = F, echo = T}
library("devtools")
devtools::install_github("rvpanaro/bsem")
```

For CRAN version:

```{r, eval = F, echo = T}
library("devtools")
install.packages("bsem")
```

During the installation, other dependencies might be required, such as ``magrittr``, ``lattice``, ``viridis``, ``coda``, ``DiagrammeR``, ``visNetwork`` and, obviously, ``rstan`` and its dependencies. Other packages are also suggested such as ``ggplot2``, ``bayesplot`` and ``tidybayes``. The default arguments used to build the ``bsem::sem`` routine will be introduced in the next sections, this is the main function of the package, as it allows the Bayesian analysis for SEM and its particular cases.

# Description

The data and additional commands are passed through the ``bsem::sem`` function:

- ``data``: a mandatory 'matrix' object where the columns are variables and the rows are observations
- ``blocks``: a mandatory named list of ``colnames`` (or integers in 1:ncol(data)) indicating the manifest variables corresponding to each block; generic names are assumed for latent variables internally if not defined
- ``paths``: list referring to the inner model paths; a list of characters or integers referring to the score's relationship; the jth first latent variable is explained if names(paths) is NULL
- ``exogenous``:     
list referring to the inner model exogenous; a list of characters or integers referring to the relationship between exogenous and latent variables; the lth first columns are explained if names(exogenous) is NULL
- ``signals``: list referring to the signals of the factor loadings initial values; must be true: (length(signals) == length(blocks)) && (lengths(signals) == lengths(blocks))
- ``row_names``: optional identifier for the observations (observation = row);
- ``prior_specs``: prior settings for the Bayesian approach; only 'normal' and 'cauchy' for gamma0, gamma and beta; 'gamma', 'lognormal' and 'inv_gamma' for sigma2 and tau2 are available, those prior specifications are ignored if not needed (FA or SEM)
- ``cores``: number of core threads to be used
- ``pars``: allows parameters to omitted in the outcome; options are any subset of default c("alpha", "lambda", "sigma2")
- ``iter``: number of iterations
- ``chains``: number of chains 
- ``scaled``: logical; indicates whether to center and scale the data; default FALSE
- ``...``: further arguments passed to Stan such as warmup, adapt_delta, and others, see rstan::sampling.



```{r, eval = F}
sem(
  data,
  blocks,
  paths,
  exogenous,
  signals,
  row_names = rownames(data),
  prior_specs = list(
    beta = c("normal(0,1)"),
    sigma2 = c("inv_gamma(2.1, 1.1)"),
    gamma0 = c("normal(0,1)"), gamma = c("normal(0,1)"),
    tau2 = c("inv_gamma(2.1, 1.1)")
  ),
  cores = parallel::detectCores(),
  pars = c("alpha", "lambda", "sigma2"),
  iter = 2000,
  chains = 4,
  scaled = FALSE,
  ...
)
```

The above function automatically selects the appropriate routine according to the specified arguments, examples are given in the following vignette. [Exploring bsem class](exploring-bsem-class.html)  has details on how to simulate datasets considering the structures described. One can reproduce the examples below by copying and pasting the following code to the ``R`` console.  For these examples, simulated artificial data was created so that we can verify that the estimates are close enough to the true parameter values used to generate the data.

# Usage

In this section, we will use simulated data from the full model described in the introduction. In many applications, with the help of technical knowledge, it is possible to establish relationships between all variables in the data set and the latent variables (constructs) studied, this characterizes the confirmatory factor analysis (CFA). Besides that,
we can also verify linear relationships between observed, latent, and/or exogenous variables. The basic structure suitable to allow bsem usage is as follows:

```{r}
dt <- bsem::simdata()
names(dt)
```

In this example, `data` is a matrix, `real` is the set of parameters used to generate the simulated data as described in the intro. `blocks`, `signals`, `paths` and `exogenous` are lists that define the modeling. It is worth mentioning that all lists are named, either by the user or internally. The `paths` should be named after ``block`` names and the `exogenous` list after the colnames of the data, i.e. variable names. The idea behind the list structure consists of describing some relationships between variables and factors in each element. For example:

```{r}
dt$exogenous
```

The latent scores ``F1`` and ``F2`` are the explanatory variables of the exogenous variable ``Y1``. The ``paths`` list also represents a linear regression model, while the ``blocks`` list determines the CFA part of the model.

```{r}
dt$blocks
```

In this example, the first 3 variables in the dataset manifest the latent variable ``F1``, we will refer to it as the first block.

```{r}
colnames(dt$data)
```

Note that the manifest variables can not include exogenous variables in ``dt$data``. Thus, the first block is expressed by ``X1``, ``X2``,  and ``X3``, as the variable ``Y`` is internally considered just for the inner part. 

``data``, ``blocks``, ``paths`` and ``exogenous`` arguments should specify the SEM model with exogenous variables:

```{r, results = F}
fit <- bsem::sem(
  data = dt$data,
  blocks = dt$blocks,
  paths = dt$paths,
  exogenous = dt$exogenous,
  signals = dt$signals,
  cores = 1,
  iter = 2000
)
```

After fitting the model we can to obtain a ``visNetwork`` graph using:

````{r}
plot(fit)
```


The ellipsoidal nodes represent the latent variables, the boxes represent the manifest variables, the dashed lines represent the linear relations among latent scores or between latent scores, and exogenous variables and the solid lines represent the relationship between the manifest and latent variables. Finally, the recursive solid lines refer to the error variance estimate of each manifest or exogenous variable. 

Also, the scores and loadings used to generate the data can be visually compared to the estimates obtained using the ``lattice`` library routines imported in ``arrayplot`` function:

```{r, echo = T}
gridExtra::grid.arrange(
  bsem::arrayplot(fit$mean_lambda, main = "estimates", mini = -5, maxi = 5),
  bsem::arrayplot(dt$real$lambda, main = "lambda (scores)", mini = -6, maxi = 6)
)  
  
gridExtra::grid.arrange(
  bsem::arrayplot(fit$mean_alpha, main = "estimates", mini = -6, maxi = 6),
  bsem::arrayplot(dt$real$alpha, main = "alpha (loadings)", mini = -6, maxi = 6),
  layout_matrix = matrix(c(1,1,2,2), ncol  = 2)
)
```

For this vignette we fitted the model using just one chain, it is recommended up to 4 chains with 2000 iterations and 1000 warmup samples (standard) to reach the equilibrium distribution. Even so, we found that the estimates follow the pattern of the true values of the parameters:

```{r, echo = F}
DT::datatable(cbind(fit$mean_beta, unlist(dt$real$beta)),caption = 'paths', colnames = c("estimate", "true"))
DT::datatable(rbind(cbind(fit$mean_gamma, c(unlist(dt$real$gamma0), unlist(dt$real$gamma))),cbind(fit$mean_tau2, unlist(dt$real$tau2))),caption = 'exogenous', colnames = c("estimate", "true"))
```

The `bsem::summary` routine prints descriptive statistics to the R console:

```{r}
summary(fit)
```

The effective sample size  ``n_eff`` gives an estimate of the independent draws from the posterior distribution, and ``Rhat`` referred to as the potential scale reduction statistic,  is one of the useful ways to monitor whether a chain has converged to the equilibrium distribution. This statistic measures the ratio between the average variation of the samples within each chain and the variation of the combined samples in the chains; if the chains have not converged to a common region, this statistic will be greater than one. Along with the estimates and posterior descriptives, the ``summary`` also provides quantities for the diagnosis of the quality of fit of the factorial model: the percentage of the total variability (of variables in X) explained by factors (``PVTE``) and the $R^2$ statistics adapted for factor analysis (``R2``). 

A crucial difference in obtaining the same statistics printed by the `bsem::summary` function is the use of the ``signals``. The signal specification, (-1 or 1) for each of the factor loadings, forces the initial values of each chain to have the same direction, and, naturally, these chains converge to nearby regions. Otherwise, the loadings signals between chains are often opposite as a consequence of random initialization. To circumvent this issue, the package automatically transforms posterior chains using simple `for` loops and `if` statements to recalculate the descriptives using `rstan::monitor`.

This page was dedicated to illustrating the commands and outcomes of the proposed package. The closing remarks section highlights the most important aspects of user-defined modeling.

# Remarks

The content of this vignette introduces the ``bsem`` package. The current version is ready for the main statistical study in the field of latent variable analysis.

The results obtained with this package vary according to the initial values set for sampling with ``NUTS``. In this sense, we provided user-defined initial values for reproducibility. Also, the number of chains, iterations, and burn-in usually can have a great influence on the analysis. Moreover, ``NUTS`` includes tuning parameters that can control the sampler's behavior, see [documentation](https://mc-stan.org/users/documentation/). From our experience, using just one chain with more iterations can be helpful and convenient depending on the number of parameters adopted in the model specification. Also, highlight the fact that the implemented routines do not support nonlinear or multilevel regression models for paths or exogenous variables.

This document is part of the content submitted to [CRAN](https://cran.r-project.org/). The package is also in public use and is available at
the GitHub development platform, the link is https://github.com/rvpanaro/bsem.



